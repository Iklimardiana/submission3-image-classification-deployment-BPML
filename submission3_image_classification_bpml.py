# -*- coding: utf-8 -*-
"""submission3-image-classification-BPML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SmxKe-qOyzixqzGze-JCqAMjaXwIyym-

Name : Iklima Mardiana

Email : iklimardiana911@gmail.com

Dataset : https://www.kaggle.com/datasets/vijaykumar1799/face-mask-detection

**Mount Google Drive**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**import**"""

import shutil
import os
import zipfile
import pathlib
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping, Callback

"""**Copy zip file to colab**"""

zip_file_path = '/content/drive/MyDrive/dataset/archive.zip'
colab_zip_path = '/content/archive.zip'
shutil.copy(zip_file_path, colab_zip_path)

"""**Extract dataset**"""

with zipfile.ZipFile(colab_zip_path, 'r') as zip_ref:
    zip_ref.extractall('/content')

"""**Directory**"""

data_dir = '/content/Dataset'
data_dir

os.listdir(data_dir)

"""**Calculate and display image distribution before deletion.**"""

image_count = len(list(pathlib.Path(data_dir).glob('*/*.jpg')))
print(f'Total images in the dataset: {image_count}')

print('\nImage Distribution:')
for i, label in enumerate(os.listdir(data_dir)):
    label_dir = os.path.join(data_dir, label)
    len_label_dir = len(os.listdir(label_dir))
    print(f'{i+1}. {label} : {len_label_dir}')

"""**Augmentation and load data**"""

BATCH_SIZE = 64
IMG_SIZE = (150, 150)

train_datagen = ImageDataGenerator(rescale=1./255.0,
                                   rotation_range=15,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest',
                                   validation_split=0.2)

"""**Flow From Directory**"""

train_generator = train_datagen.flow_from_directory(data_dir,
                                                    target_size=IMG_SIZE,
                                                    batch_size=BATCH_SIZE,
                                                    class_mode='categorical',
                                                    subset='training')

validation_generator = train_datagen.flow_from_directory(data_dir,
                                                         target_size=IMG_SIZE,
                                                         batch_size=BATCH_SIZE,
                                                         class_mode='categorical',
                                                         subset='validation')

"""**Model**"""

model = tf.keras.models.Sequential([
    VGG16(weights="imagenet", include_top=False, input_tensor=Input(shape=(150, 150, 3))),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),

    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Display the summary of the model
model.summary()

"""**Compile the model**"""

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(learning_rate=0.0001),
              metrics=['accuracy'])

"""**Callback to stop training when both training and validation accuracy reach 90%**"""

class myCallback(tf.keras.callbacks.Callback):
  def __init__(self, min_epochs=10):
    self.min_epochs = min_epochs
    self.epochs_passed = 0

  def on_epoch_end(self, epoch, logs={}):
    self.epochs_passed += 1

    if self.epochs_passed >= self.min_epochs and logs.get('accuracy') > 0.9:
      print(f"Training stopped as both training and validation accuracy reached 90% after {self.epochs_passed} epochs")
      self.model.stop_training = True

callbacks = myCallback()

early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)

"""**Train the model**"""

history = model.fit(
    train_generator,
    epochs=100,
    validation_data=validation_generator,
    validation_steps=5,
    verbose=2,
    callbacks=[callbacks, early_stopping]
)

import matplotlib.pyplot as plt
plt.style.use('seaborn')

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
plt.plot(accuracy, label='Training Accuracy')
plt.plot(val_accuracy, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

"""**Testing Model**"""

print(train_generator.class_indices)

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  path = fn
  img = image.load_img(path, target_size=(150, 150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=32)
  print(fn)
  if classes[0][0]==1:
    print('mask_weared_incorrect')
  elif classes[0][1]==1:
    print('with_mask')
  elif classes[0][2]==1:
    print('without_mask')
  else:
    print('UNKNOWN')

"""**Save model to SavedModel format**"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

"""**Convert SavedModel to vegs.tflite**"""

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)